

Design Questions
----------------


naming:
  * unique class names: `Model`
  * `getsomething`: indicates a return
  * fit: use consistently as verb, not also as noun

public classes that are iterators have non public methods
  * proposal convert iterator to loop

are all one linear methods necessary?

interface:
  * leave open to allow extension to arrays, masked, structured, record arrays
	and formula
  * need extra information, such as variable names for `print` (string return)
	and plots

formula:
  *	design?
	It's not clear to me what the benefits of current formula framework are.
	It's pretty verbose. short hand notation?

How to return results?
  * result classes with largely common interface, or attached to estimator
    class as properties, or a mixture of the two?
  * residual analysis, separate or attached to estimator class
    How much does residual analysis depend on specific properties of the
    estimator? Check how much commonality.
    example sandwich estimators
  * test statistics in separate functions, so that they can also be used
    without using the estimator class?
  * presentation: return string for printing summary, plots. What is the best
    pattern?

Algorithm
  * treatment of unidentified models: singularity, multicollinearity,
    user needs at least a warning
    - linear: use of pinv for covariance matrix of parameter estimates
      by default?
    - non-linear: singular Hessian
  * rescaling: optional, or is it done by linalg.leastsq?
  * estimator classes: for later, least squares, iterative, maximum
    likelihood, EM, generalized method of moments, robust
    often equivalent, but also often there are differences in assumptions
    and performance. How do we select which ones to use and how to give
    user the option, different classes, optional keywords?


Terminology (applies also to pymvpa)
  * some is not familiar to me
  * need glossary, translation to other commonly used statistical/econometrics
    terms
  * examples:
    - contrast: is this just a test of linear restriction, tcontrast, fcontrast;
      relationship to dummy variables in linear regression
    - features: in pymvpa, are these always discrete random variables (ordinal
      or categorical)?

Use cases
  * look at some introductory usage explanations in R, SAS, ..., text books
    for example: "Econometrics with R" author?
    This is obvious for basic results, but not for additional test statistics


Specific Models
---------------

mixed
^^^^^
* no tests, capitalization was wrong, fixed
* uses formula, can it be used without
* does repeated measures just mean: panel data with random effects and maybe
  missing data?
* not used in nipy
* competing implementation in neurospin
* it's pretty slow, creating a class for each unit is pretty "heavy",
  can this be rewritten using arrays of numbers?
* lower priority since it's not used and I'm not familiar with this
* to cover a similar case, I would like a panel data model class with
  fixed and random effects and OLS or (reduced?) Maximum Likelihood
  estimators. What's the difference to EM algorithm, generality, correlation
  structure and so on?

cox
^^^
* no tests, fixed capitalization, now runs
* not used anywhere in nipy
* uses tempfile in cache, needs testing whether it works correctly on Windows,
  - currently not used, only build if method is directly called
  - it works but it doesn't clean up on windows
  - __del__ method has problems on shutdown, added try except
* uses formula, can it be used without
* survival.py has thin classes, used for Observation
* cox is similar to mixed with heavy use of classes for each observation


gam
^^^
 * no tests
 * use _hbspline, running gam.py crashed before, is this fixed? No.
 * make it more general (if it is not yet), to work with any non parametric
   regression not just splines, see notes on bspline
 * references: Hastie, Tibshirani (1986), Friedman, Hastie, Tibshirani (2001)
   Oliver Linton (with Haerdle?), Horowitz?,
      David Ruppert, M. P.Wand, R. J. Carroll (2003)?
      Rasmussen, Williams (2006): Gaussian Processes for Machine Learning
 * quickfix to see if gam can be run with other smoothers
   - replace call to smoothingspline with call to polysmoother, currently
     messed up but it runs without exception and crash.
   - needs a lot of bugfixing, now that gam itself is running without the
     crashing bsplines




smoother
^^^^^^^^
  * no tests, no examples to run
  * uses _hbspline, need example to see if it crashes


bspline
^^^^^^^
  * still segfaults, e.g.
    >>> execfile(r'C:\pathto\nipy\fixes\scipy\stats\models\gam.py')
  * bspline is too hard to fix and maintain,
    can bspline_ext.c be replaced by a cython wrapper to bspline_impl.c?
    or rewrite everything in cython?
  * What's the reference? Searching for b-spline regression doesn't yield
    much. I found some references in GAM models
    Is this a popular and useful method compared for example to using
    kernel trick as in kernel (ridge) regression or gaussian processes.
  * What are the alternatives for use in generalized additive models?
    can scipy.interpolate (fitpack) be used instead?


random notes
------------

  * need ddof as keyword parameters for preprocessed data to get correct
    test statistics, e.g. if mean or group means are already removed.
    relevant eg. for ols, panel data, fixed effects
  * tempfiles for cache: I just saw that django (BSD license) has a windows
    compatible named temporary file class, that looks useful
    http://code.djangoproject.com/browser/django/trunk/django/core/files/temp.py
