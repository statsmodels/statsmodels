{
 "metadata": {
  "name": "",
  "signature": "sha256:30df103faac483b6fe86d3c40f0006ab108cfa420220d1a9622366673a25ed91"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "1D Kernel Density Estimation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "from scipy import stats\n",
      "import statsmodels.api as sm\n",
      "import matplotlib.pyplot as plt\n",
      "from statsmodels.distributions.mixture_rvs import mixture_rvs\n",
      "from statsmodels.kernel_methods import bandwidths"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A simple example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To start with, we'll look at estimating the density of a mixture of gaussian kernels, just to see the simplest use case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(12345)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs_dist1 = mixture_rvs([.25,.75], size=10000, dist=[stats.norm, stats.norm],\n",
      "                kwargs = (dict(loc=-1,scale=.5),dict(loc=1,scale=.5)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kde = sm.kernel_methods.KDE(obs_dist1)\n",
      "mod = kde.fit()\n",
      "support, density = mod.grid()\n",
      "mod.bandwidth"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(12, 8))\n",
      "ax = fig.add_subplot(111)\n",
      "ax.hist(obs_dist1, bins=50, normed=True, color='red', alpha=.5)\n",
      "ax.plot(support, density, lw=2, color='black');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bounded domain"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a second example, we will look at a mixture between a normal and beta distribution, such that the domain is bounded on one side."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs_dist2 = mixture_rvs([.25,.75], size=10000, dist=[stats.norm, stats.beta],\n",
      "            kwargs = (dict(loc=-1,scale=.5),dict(loc=1,scale=1,args=(1,.5))))\n",
      "def pdf_dist2(x):\n",
      "    return stats.norm(loc=-1, scale=.5).pdf(x) *.25 + stats.beta(1, .5, loc=1, scale=1).pdf(x)*.75"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, let's see what happens if we don't mention the upper bound on the beta distribution:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kde = sm.kernel_methods.KDE(obs_dist2)\n",
      "mod = kde.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs1, ys1 = mod.grid()\n",
      "xs1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that, naturally, the expected support of the distribution extend beyond the support of the beta distribution (in our case, it stops at 2). And we can see in the following plot that the peak is badly estimated:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(12, 8))\n",
      "ax = fig.add_subplot(111)\n",
      "ax.hist(obs_dist2, bins=50, normed=True, color='red', alpha=.5)\n",
      "ax.plot(xs1, ys1, lw=2, color='black')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also see that stopping the domain at 2 on the evaluation, we \"loose\" some mass in the density (nearly 10% of it):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gr = sm.kernel_methods.Grid.fromBounds([-4, 2], shape=1024)\n",
      "ys = mod(gr)\n",
      "print(\"Sum of the density:\", gr.integrate(ys))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, if we fix the upper bound ... we don't loose any more mass"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kde.upper = 2\n",
      "mod2 = kde.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs2, ys2 = mod2.grid()\n",
      "print(\"Total density:\", xs2.integrate(ys2))\n",
      "xs2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(12, 8))\n",
      "ax = fig.gca()\n",
      "ax.hist(obs_dist2, bins=50, normed=True, color='red', alpha=.5)\n",
      "ax.plot(xs2, ys2, lw=2, color='black')\n",
      "ax.plot(xs2, pdf_dist2(xs2), color='blue', linestyle='--')\n",
      "ax.set_ylim(0, 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, we can see that the peak, although better estimated, is still largely under-estimated by this method!\n",
      "\n",
      "This is because the default method has been chosen to be fast and reasonable is many cases, but not if the distribution diverges on the boundary. For this case, a better method is the first order approximation called 'linear combination':"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kde.method = sm.kernel_methods.kde_methods.LinearCombination\n",
      "mod3 = kde.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs3, ys3 = mod3.grid()\n",
      "print(\"Total density: \", xs3.integrate(ys3))  # Using the integrate method of the Grid object"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can note that, due to the first order approximation, the total density is not quite 1. In this particular case, it is over-estimated by about 5%. But when we plt the graph, we can see that the peak is much better approximated now:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(12, 8))\n",
      "ax = fig.gca()\n",
      "ax.hist(obs_dist2, bins=50, normed=True, color='red', alpha=.5)\n",
      "ax.plot(xs3, ys3, lw=2, color='black', label='KDE estimate')\n",
      "ax.plot(xs3, pdf_dist2(xs3), color='blue', linestyle='--', label='Real PDF')\n",
      "ax.set_ylim(0, 4)\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At last, we can see the bandwidth is slightly over-estimated. We could expect this, as the default method is Scotts method, which is optimal for a single gaussian. In our case, the extra beta function will lead to an over-estimation of the ideal bandwidth. We can, however, do this by hand:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kde.adjust = 0.5\n",
      "mod4 = kde.fit()\n",
      "xs4, ys4 = mod4.grid()\n",
      "print(\"Total density: \", xs4.integrate(ys4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(12, 8))\n",
      "ax = fig.gca()\n",
      "ax.hist(obs_dist2, bins=50, normed=True, color='red', alpha=.5)\n",
      "ax.plot(xs4, ys4, lw=2, color='black', label='KDE estimate')\n",
      "ax.plot(xs4, pdf_dist2(xs4), color='blue', linestyle='--', label='Real PDF')\n",
      "ax.set_ylim(0, 4)\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(12, 8))\n",
      "ax = fig.gca()\n",
      "ax.plot(xs4, pdf_dist2(xs4), label='Real PDF', color='blue', linestyle='--')\n",
      "ax.plot(xs1, ys1, label='Unbounded estimate')\n",
      "ax.plot(xs2, ys2, label='Reflective boundary')\n",
      "ax.plot(xs3, ys3, label='Linear combination')\n",
      "ax.plot(xs4, ys4, label='LC - cross validation')\n",
      "plt.legend(loc='upper left')\n",
      "ax.set_title('Comparison of the various methods')\n",
      "ax.set_xlim(-3, 2)\n",
      "ax.set_ylim(0, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Other functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to the PDF, 1D methods also provide:\n",
      "\n",
      "* Cumulative Density Function\n",
      "* Survival function\n",
      "* Hazard function\n",
      "* ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs, ys = mod4.cdf_grid()\n",
      "f = plt.figure(figsize=(12, 8))\n",
      "ax = f.add_subplot(111)\n",
      "ax.plot(xs, ys)\n",
      "ax.set_title('CDF')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs, ys = mod4.sf_grid()\n",
      "f = plt.figure(figsize=(12, 8))\n",
      "ax = f.add_subplot(111)\n",
      "ax.plot(xs, ys)\n",
      "ax.set_title('Survival function')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs, ys = mod4.icdf_grid()\n",
      "f = plt.figure(figsize=(12, 8))\n",
      "ax = f.add_subplot(111)\n",
      "ax.plot(xs, ys)\n",
      "ax.set_title('Inverse CDF')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}